# nbdev-double-descent-dar


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

Reproducing the ideas from this wonderful paper:

Yehuda Dar, Muthukumar, V., & Baraniuk, R. (2021). A Farewell to the
Bias-Variance Tradeoff? An Overview of the Theory of Overparameterized
Machine Learning. https://arxiv.org/abs/2109.02355

Fully explained in:

- Blog post:
  https://medium.com/@jeanimal/technical-even-linear-regression-can-escape-the-bias-variance-tradeoff-263abe6acb1c
- Video: https://youtu.be/bM6WJVyytEg

Code:

- This reproduction is in python.
- A reproduction in R is here:
  https://github.com/jeanimal/farewell_bias_variance

## Install

``` sh
pip install nbdev_double_descent_dar
```

## How to use

Fill me in please! Donâ€™t forget code examples:

``` python
import pandas as pd
```

``` python
X = pd.DataFrame({'a':range(1,10), 'b':range(2,11), 'c':range(3,12)})
y = pd.DataFrame({'target':range(100,110)})
X, y
```

    (   a   b   c
     0  1   2   3
     1  2   3   4
     2  3   4   5
     3  4   5   6
     4  5   6   7
     5  6   7   8
     6  7   8   9
     7  8   9  10
     8  9  10  11,
        target
     0     100
     1     101
     2     102
     3     103
     4     104
     5     105
     6     106
     7     107
     8     108
     9     109)

``` python
random_state=1
num_rows=3
num_cols=2

X_sub, y_sub = sample_rows_and_cols(X, y, num_rows, num_cols, random_state=random_state, replace=False)
```

``` python
X_sub, y_sub
```

    (   a  c
     5  6  8
     1  2  4
     6  7  9,
        target
     5     105
     1     101
     6     106)
